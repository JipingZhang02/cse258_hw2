{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(parseData(\"beer_50000.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = data[:25000]\n",
    "dataValid = data[25000:37500]\n",
    "dataTest = data[37500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = [d['beer/ABV'] > 7 for d in dataTrain]\n",
    "yValid = [d['beer/ABV'] > 7 for d in dataValid]\n",
    "yTest = [d['beer/ABV'] > 7 for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryCounts = defaultdict(int)\n",
    "for d in data:\n",
    "    categoryCounts[d['beer/style']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [c for c in categoryCounts if categoryCounts[c] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "catID = dict(zip(list(categories),range(len(categories))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_column_names = [kname for kname in data[0] if ((\"review\" in kname) and isinstance(data[0][kname],float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = max(len(datum['review/text']) for datum in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(datum, includeCat = True, includeReview = True, includeLength = True, ret_np_array = False):\n",
    "    res = list()\n",
    "    if includeCat:\n",
    "        catID_1hot_vector = [0.0]*(len(catID))\n",
    "        style_this = datum['beer/style']\n",
    "        if style_this in catID:\n",
    "            catID_1hot_vector[catID[style_this]]=1.0\n",
    "        res.extend(catID_1hot_vector)\n",
    "    if includeReview:\n",
    "        for review_col_name in review_column_names:\n",
    "            res.append(datum[review_col_name]/5.0)\n",
    "    if includeLength:\n",
    "        res.append(len(datum['review/text'])/max_text_len)\n",
    "    assert len(res)>0,f\"the feat function returns no feature for datum {datum}\"\n",
    "    if ret_np_array:\n",
    "        res = np.array(res,dtype=float)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin_reg = linear_model.LinearRegression()\n",
    "# lin_reg.fit()\n",
    "# lin_reg.predict()\n",
    "\n",
    "def get_performance_info(y_actual,y_predict):\n",
    "    if not isinstance(y_actual,np.ndarray):\n",
    "        y_actual = np.array(y_actual)\n",
    "    y_actual = y_actual.reshape((-1,))\n",
    "    y_predict = y_predict.reshape((-1,))\n",
    "    TP = np.sum((y_actual == 1) & (y_predict == 1))\n",
    "    FP = np.sum((y_actual == 0) & (y_predict == 1))\n",
    "    TN = np.sum((y_actual == 0) & (y_predict == 0))\n",
    "    FN = np.sum((y_actual == 1) & (y_predict == 0))\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FNR = FN / (TP + FN)\n",
    "    BER = 1 - (0.5 * (TPR + TNR))\n",
    "    return TP,FP,TN,FN,TPR, FPR, TNR, FNR, BER\n",
    "\n",
    "def pipeline(reg, includeCat = True, includeReview = True, includeLength = True):\n",
    "    get_x_row = lambda datum:feat(datum,includeCat=includeCat,includeReview=includeReview,includeLength=includeLength)\n",
    "    get_all_x = lambda data:np.array(list(get_x_row(datum) for datum in data),dtype=float)\n",
    "    x_train = get_all_x(dataTrain)\n",
    "    x_valid = get_all_x(dataValid)\n",
    "    x_test = get_all_x(dataTest)\n",
    "    logisticRegModel = linear_model.LogisticRegression(class_weight=\"balanced\",penalty=\"l2\",C=reg)\n",
    "    logisticRegModel.fit(x_train,yTrain)\n",
    "    y_pred_valid = logisticRegModel.predict(x_valid)>=0.5\n",
    "    y_pred_test = logisticRegModel.predict(x_test)>=0.5\n",
    "    return logisticRegModel,get_performance_info(yValid,y_pred_valid)[-1],get_performance_info(yTest,y_pred_test)[-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, validBER, testBER = pipeline(10, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [validBER, testBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "mod2, validBER2, testBER2 = pipeline(10, True, True, True)\n",
    "answers['Q2'] = [validBER2, testBER2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "best_c,best_model,min_ber_valid,ber_test = 0,None,1.0,1.0\n",
    "for c in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    model,ber_valid,b_t_this = pipeline(c,True,True,True)\n",
    "    if ber_valid<min_ber_valid:\n",
    "        best_c = c\n",
    "        best_model = model\n",
    "        min_ber_valid = ber_valid\n",
    "        ber_test = b_t_this\n",
    "\n",
    "answers['Q3'] = [best_c,min_ber_valid,ber_test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, validBER, testBER_noCat = pipeline(1.0,False,True,True)\n",
    "mod, validBER, testBER_noReview = pipeline(1.0,True,False,True)\n",
    "mod, validBER, testBER_noLength = pipeline(1.0,True,True,False)\n",
    "answers['Q4'] = [testBER_noCat, testBER_noReview, testBER_noLength]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': [0.16130237168160533, 0.1607838024608832],\n",
       " 'Q2': [0.14190530394736312, 0.1430222366785745],\n",
       " 'Q3': [1, 0.14142076181125796, 0.14220884792124866],\n",
       " 'Q4': [0.3122273694930058, 0.16109632033831978, 0.1461270153739065]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
